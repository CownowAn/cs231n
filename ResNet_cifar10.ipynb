{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet_cifar10.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMt/4byVdCDSEAXnQ7jLopf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d43de4e93c374729a266967f455cc1f3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_87a6f320a84f4987b6045a12f5d21c37","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1589c8e3cfa84f48956da12690e6f5bc","IPY_MODEL_d8d868341d3b4c729af5015f83974c20","IPY_MODEL_41dba243fb7243f982626d3fb726dc04"]}},"87a6f320a84f4987b6045a12f5d21c37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1589c8e3cfa84f48956da12690e6f5bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b4418cd09ef342ad91c806a67e151480","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8349e0fab82c40139c7cce3ae847b44c"}},"d8d868341d3b4c729af5015f83974c20":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d79285bd260146198b93e7d892042900","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":102530333,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":102530333,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0393efce285242cc95e8d2cbd0157f56"}},"41dba243fb7243f982626d3fb726dc04":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a24fd4bddc42430382403e12e2f9459e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 97.8M/97.8M [00:00&lt;00:00, 227MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_23eaea8e9a2b47798d72937e3410f955"}},"b4418cd09ef342ad91c806a67e151480":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8349e0fab82c40139c7cce3ae847b44c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d79285bd260146198b93e7d892042900":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0393efce285242cc95e8d2cbd0157f56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a24fd4bddc42430382403e12e2f9459e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"23eaea8e9a2b47798d72937e3410f955":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"6fUP_KBvz06B","executionInfo":{"status":"ok","timestamp":1642594934203,"user_tz":-540,"elapsed":288,"user":{"displayName":"Sohyun An","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiA5fbxTFul4oSf0J-aANYw-cKEXK7BcQfHqodu=s64","userId":"03040571318498638819"}}},"outputs":[],"source":["from torchsummary import summary\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torch.utils.data import sampler\n","\n","import torchvision.datasets as dset\n","import torchvision.transforms as T\n","from torchvision import models\n","from torchvision import utils\n","\n","import numpy as np"]},{"cell_type":"code","source":["USE_GPU = True\n","dtype = torch.float32 # We will be using float throughout this tutorial.\n","\n","if USE_GPU and torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","\n","# Constant to control how frequently we print train loss.\n","print_every = 100\n","print('using device:', device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XW55r7WAcY-E","executionInfo":{"status":"ok","timestamp":1642594937168,"user_tz":-540,"elapsed":317,"user":{"displayName":"Sohyun An","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiA5fbxTFul4oSf0J-aANYw-cKEXK7BcQfHqodu=s64","userId":"03040571318498638819"}},"outputId":"cb9a3a1c-c3e5-43d7-9523-127d4caf7f86"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["using device: cuda\n"]}]},{"cell_type":"code","source":["NUM_TRAIN = 49000\n","\n","transform_train = T.Compose([\n","                      # T.RandomResizedCrop(32),\n","                      # T.RandomHorizontalFlip(),\n","                      # T.Resize(256), T.CenterCrop(224),\n","                      # T.AutoAugment(policy=T.AutoAugmentPolicy.CIFAR10),\n","                      T.RandomCrop(32, padding=4),\n","                      T.RandomHorizontalFlip(),\n","                      T.ToTensor(), \n","                      T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","                      ])\n","\n","transform_test = T.Compose([\n","                      T.ToTensor(), \n","                      T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","                      ])\n","\n","cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n","                             transform=transform_train)\n","loader_train = DataLoader(cifar10_train, batch_size=64, \n","                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n","\n","cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n","                           transform=transform_test)\n","loader_val = DataLoader(cifar10_val, batch_size=64, \n","                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n","\n","cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True, \n","                            transform=transform_test)\n","loader_test = DataLoader(cifar10_test, batch_size=64)"],"metadata":{"id":"Pv4RAgb6z_6L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642594968093,"user_tz":-540,"elapsed":2627,"user":{"displayName":"Sohyun An","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiA5fbxTFul4oSf0J-aANYw-cKEXK7BcQfHqodu=s64","userId":"03040571318498638819"}},"outputId":"9c7d6776-0d18-47c8-de9d-c540e8f24cd6"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["!pip install torchsummary"],"metadata":{"id":"emVNucfC0Bsw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642594973621,"user_tz":-540,"elapsed":3215,"user":{"displayName":"Sohyun An","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiA5fbxTFul4oSf0J-aANYw-cKEXK7BcQfHqodu=s64","userId":"03040571318498638819"}},"outputId":"f7a5f27a-b118-4d33-b1dd-b8e7e4673fa7"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"]}]},{"cell_type":"code","source":["def check_accuracy(loader, model):\n","    if loader.dataset.train:\n","        print('Checking accuracy on validation set')\n","    else:\n","        print('Checking accuracy on test set')   \n","    num_correct = 0\n","    num_samples = 0\n","    model.eval()  # set model to evaluation mode\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.long)\n","            scores = model(x)\n","            _, preds = scores.max(1)\n","            num_correct += (preds == y).sum()\n","            num_samples += preds.size(0)\n","        acc = float(num_correct) / num_samples\n","        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n","        return acc"],"metadata":{"id":"l3riOVZEeqoa","executionInfo":{"status":"ok","timestamp":1642594987754,"user_tz":-540,"elapsed":281,"user":{"displayName":"Sohyun An","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiA5fbxTFul4oSf0J-aANYw-cKEXK7BcQfHqodu=s64","userId":"03040571318498638819"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def train(model, optimizer, scheduler, epochs=1):\n","    model = model.to(device=device)\n","    for e in range(epochs):\n","        print(f\"--------------------  Epoch: {e+1}  --------------------\")\n","        for t, (x, y) in enumerate(loader_train):\n","            model.train()  # put model to training mode\n","            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.long)\n","\n","            scores = model(x)\n","            loss = F.cross_entropy(scores, y)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            # Gradient clipping\n","            if grad_clip: \n","                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n","            optimizer.step()\n","\n","            if t % print_every == 0:\n","                print('Epoch %d' % (e+1))\n","                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n","                val_acc = check_accuracy(loader_val, model)\n","                print()\n","\n","        scheduler.step()"],"metadata":{"id":"O8NYWO0ueG4Z","executionInfo":{"status":"ok","timestamp":1642594996578,"user_tz":-540,"elapsed":299,"user":{"displayName":"Sohyun An","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiA5fbxTFul4oSf0J-aANYw-cKEXK7BcQfHqodu=s64","userId":"03040571318498638819"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["model = models.resnet50(pretrained=True)\n","num_features = model.fc.in_features\n","model.fc = torch.nn.Linear(num_features, 10)\n","model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","model.maxpool = nn.Identity()\n","model = model.to(device)\n","print(model.conv1)\n","summary(model, (3, 32, 32))"],"metadata":{"id":"tSAWg30J0GdM","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d43de4e93c374729a266967f455cc1f3","87a6f320a84f4987b6045a12f5d21c37","1589c8e3cfa84f48956da12690e6f5bc","d8d868341d3b4c729af5015f83974c20","41dba243fb7243f982626d3fb726dc04","b4418cd09ef342ad91c806a67e151480","8349e0fab82c40139c7cce3ae847b44c","d79285bd260146198b93e7d892042900","0393efce285242cc95e8d2cbd0157f56","a24fd4bddc42430382403e12e2f9459e","23eaea8e9a2b47798d72937e3410f955"]},"executionInfo":{"status":"ok","timestamp":1642595033837,"user_tz":-540,"elapsed":11284,"user":{"displayName":"Sohyun An","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiA5fbxTFul4oSf0J-aANYw-cKEXK7BcQfHqodu=s64","userId":"03040571318498638819"}},"outputId":"b493d624-9e46-4e31-fd89-ec70c15b5fdb"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d43de4e93c374729a266967f455cc1f3","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/97.8M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]           1,728\n","       BatchNorm2d-2           [-1, 64, 32, 32]             128\n","              ReLU-3           [-1, 64, 32, 32]               0\n","          Identity-4           [-1, 64, 32, 32]               0\n","            Conv2d-5           [-1, 64, 32, 32]           4,096\n","       BatchNorm2d-6           [-1, 64, 32, 32]             128\n","              ReLU-7           [-1, 64, 32, 32]               0\n","            Conv2d-8           [-1, 64, 32, 32]          36,864\n","       BatchNorm2d-9           [-1, 64, 32, 32]             128\n","             ReLU-10           [-1, 64, 32, 32]               0\n","           Conv2d-11          [-1, 256, 32, 32]          16,384\n","      BatchNorm2d-12          [-1, 256, 32, 32]             512\n","           Conv2d-13          [-1, 256, 32, 32]          16,384\n","      BatchNorm2d-14          [-1, 256, 32, 32]             512\n","             ReLU-15          [-1, 256, 32, 32]               0\n","       Bottleneck-16          [-1, 256, 32, 32]               0\n","           Conv2d-17           [-1, 64, 32, 32]          16,384\n","      BatchNorm2d-18           [-1, 64, 32, 32]             128\n","             ReLU-19           [-1, 64, 32, 32]               0\n","           Conv2d-20           [-1, 64, 32, 32]          36,864\n","      BatchNorm2d-21           [-1, 64, 32, 32]             128\n","             ReLU-22           [-1, 64, 32, 32]               0\n","           Conv2d-23          [-1, 256, 32, 32]          16,384\n","      BatchNorm2d-24          [-1, 256, 32, 32]             512\n","             ReLU-25          [-1, 256, 32, 32]               0\n","       Bottleneck-26          [-1, 256, 32, 32]               0\n","           Conv2d-27           [-1, 64, 32, 32]          16,384\n","      BatchNorm2d-28           [-1, 64, 32, 32]             128\n","             ReLU-29           [-1, 64, 32, 32]               0\n","           Conv2d-30           [-1, 64, 32, 32]          36,864\n","      BatchNorm2d-31           [-1, 64, 32, 32]             128\n","             ReLU-32           [-1, 64, 32, 32]               0\n","           Conv2d-33          [-1, 256, 32, 32]          16,384\n","      BatchNorm2d-34          [-1, 256, 32, 32]             512\n","             ReLU-35          [-1, 256, 32, 32]               0\n","       Bottleneck-36          [-1, 256, 32, 32]               0\n","           Conv2d-37          [-1, 128, 32, 32]          32,768\n","      BatchNorm2d-38          [-1, 128, 32, 32]             256\n","             ReLU-39          [-1, 128, 32, 32]               0\n","           Conv2d-40          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-41          [-1, 128, 16, 16]             256\n","             ReLU-42          [-1, 128, 16, 16]               0\n","           Conv2d-43          [-1, 512, 16, 16]          65,536\n","      BatchNorm2d-44          [-1, 512, 16, 16]           1,024\n","           Conv2d-45          [-1, 512, 16, 16]         131,072\n","      BatchNorm2d-46          [-1, 512, 16, 16]           1,024\n","             ReLU-47          [-1, 512, 16, 16]               0\n","       Bottleneck-48          [-1, 512, 16, 16]               0\n","           Conv2d-49          [-1, 128, 16, 16]          65,536\n","      BatchNorm2d-50          [-1, 128, 16, 16]             256\n","             ReLU-51          [-1, 128, 16, 16]               0\n","           Conv2d-52          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-53          [-1, 128, 16, 16]             256\n","             ReLU-54          [-1, 128, 16, 16]               0\n","           Conv2d-55          [-1, 512, 16, 16]          65,536\n","      BatchNorm2d-56          [-1, 512, 16, 16]           1,024\n","             ReLU-57          [-1, 512, 16, 16]               0\n","       Bottleneck-58          [-1, 512, 16, 16]               0\n","           Conv2d-59          [-1, 128, 16, 16]          65,536\n","      BatchNorm2d-60          [-1, 128, 16, 16]             256\n","             ReLU-61          [-1, 128, 16, 16]               0\n","           Conv2d-62          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-63          [-1, 128, 16, 16]             256\n","             ReLU-64          [-1, 128, 16, 16]               0\n","           Conv2d-65          [-1, 512, 16, 16]          65,536\n","      BatchNorm2d-66          [-1, 512, 16, 16]           1,024\n","             ReLU-67          [-1, 512, 16, 16]               0\n","       Bottleneck-68          [-1, 512, 16, 16]               0\n","           Conv2d-69          [-1, 128, 16, 16]          65,536\n","      BatchNorm2d-70          [-1, 128, 16, 16]             256\n","             ReLU-71          [-1, 128, 16, 16]               0\n","           Conv2d-72          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-73          [-1, 128, 16, 16]             256\n","             ReLU-74          [-1, 128, 16, 16]               0\n","           Conv2d-75          [-1, 512, 16, 16]          65,536\n","      BatchNorm2d-76          [-1, 512, 16, 16]           1,024\n","             ReLU-77          [-1, 512, 16, 16]               0\n","       Bottleneck-78          [-1, 512, 16, 16]               0\n","           Conv2d-79          [-1, 256, 16, 16]         131,072\n","      BatchNorm2d-80          [-1, 256, 16, 16]             512\n","             ReLU-81          [-1, 256, 16, 16]               0\n","           Conv2d-82            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-83            [-1, 256, 8, 8]             512\n","             ReLU-84            [-1, 256, 8, 8]               0\n","           Conv2d-85           [-1, 1024, 8, 8]         262,144\n","      BatchNorm2d-86           [-1, 1024, 8, 8]           2,048\n","           Conv2d-87           [-1, 1024, 8, 8]         524,288\n","      BatchNorm2d-88           [-1, 1024, 8, 8]           2,048\n","             ReLU-89           [-1, 1024, 8, 8]               0\n","       Bottleneck-90           [-1, 1024, 8, 8]               0\n","           Conv2d-91            [-1, 256, 8, 8]         262,144\n","      BatchNorm2d-92            [-1, 256, 8, 8]             512\n","             ReLU-93            [-1, 256, 8, 8]               0\n","           Conv2d-94            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-95            [-1, 256, 8, 8]             512\n","             ReLU-96            [-1, 256, 8, 8]               0\n","           Conv2d-97           [-1, 1024, 8, 8]         262,144\n","      BatchNorm2d-98           [-1, 1024, 8, 8]           2,048\n","             ReLU-99           [-1, 1024, 8, 8]               0\n","      Bottleneck-100           [-1, 1024, 8, 8]               0\n","          Conv2d-101            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-102            [-1, 256, 8, 8]             512\n","            ReLU-103            [-1, 256, 8, 8]               0\n","          Conv2d-104            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-105            [-1, 256, 8, 8]             512\n","            ReLU-106            [-1, 256, 8, 8]               0\n","          Conv2d-107           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-108           [-1, 1024, 8, 8]           2,048\n","            ReLU-109           [-1, 1024, 8, 8]               0\n","      Bottleneck-110           [-1, 1024, 8, 8]               0\n","          Conv2d-111            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-112            [-1, 256, 8, 8]             512\n","            ReLU-113            [-1, 256, 8, 8]               0\n","          Conv2d-114            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-115            [-1, 256, 8, 8]             512\n","            ReLU-116            [-1, 256, 8, 8]               0\n","          Conv2d-117           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-118           [-1, 1024, 8, 8]           2,048\n","            ReLU-119           [-1, 1024, 8, 8]               0\n","      Bottleneck-120           [-1, 1024, 8, 8]               0\n","          Conv2d-121            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-122            [-1, 256, 8, 8]             512\n","            ReLU-123            [-1, 256, 8, 8]               0\n","          Conv2d-124            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-125            [-1, 256, 8, 8]             512\n","            ReLU-126            [-1, 256, 8, 8]               0\n","          Conv2d-127           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-128           [-1, 1024, 8, 8]           2,048\n","            ReLU-129           [-1, 1024, 8, 8]               0\n","      Bottleneck-130           [-1, 1024, 8, 8]               0\n","          Conv2d-131            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-132            [-1, 256, 8, 8]             512\n","            ReLU-133            [-1, 256, 8, 8]               0\n","          Conv2d-134            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-135            [-1, 256, 8, 8]             512\n","            ReLU-136            [-1, 256, 8, 8]               0\n","          Conv2d-137           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-138           [-1, 1024, 8, 8]           2,048\n","            ReLU-139           [-1, 1024, 8, 8]               0\n","      Bottleneck-140           [-1, 1024, 8, 8]               0\n","          Conv2d-141            [-1, 512, 8, 8]         524,288\n","     BatchNorm2d-142            [-1, 512, 8, 8]           1,024\n","            ReLU-143            [-1, 512, 8, 8]               0\n","          Conv2d-144            [-1, 512, 4, 4]       2,359,296\n","     BatchNorm2d-145            [-1, 512, 4, 4]           1,024\n","            ReLU-146            [-1, 512, 4, 4]               0\n","          Conv2d-147           [-1, 2048, 4, 4]       1,048,576\n","     BatchNorm2d-148           [-1, 2048, 4, 4]           4,096\n","          Conv2d-149           [-1, 2048, 4, 4]       2,097,152\n","     BatchNorm2d-150           [-1, 2048, 4, 4]           4,096\n","            ReLU-151           [-1, 2048, 4, 4]               0\n","      Bottleneck-152           [-1, 2048, 4, 4]               0\n","          Conv2d-153            [-1, 512, 4, 4]       1,048,576\n","     BatchNorm2d-154            [-1, 512, 4, 4]           1,024\n","            ReLU-155            [-1, 512, 4, 4]               0\n","          Conv2d-156            [-1, 512, 4, 4]       2,359,296\n","     BatchNorm2d-157            [-1, 512, 4, 4]           1,024\n","            ReLU-158            [-1, 512, 4, 4]               0\n","          Conv2d-159           [-1, 2048, 4, 4]       1,048,576\n","     BatchNorm2d-160           [-1, 2048, 4, 4]           4,096\n","            ReLU-161           [-1, 2048, 4, 4]               0\n","      Bottleneck-162           [-1, 2048, 4, 4]               0\n","          Conv2d-163            [-1, 512, 4, 4]       1,048,576\n","     BatchNorm2d-164            [-1, 512, 4, 4]           1,024\n","            ReLU-165            [-1, 512, 4, 4]               0\n","          Conv2d-166            [-1, 512, 4, 4]       2,359,296\n","     BatchNorm2d-167            [-1, 512, 4, 4]           1,024\n","            ReLU-168            [-1, 512, 4, 4]               0\n","          Conv2d-169           [-1, 2048, 4, 4]       1,048,576\n","     BatchNorm2d-170           [-1, 2048, 4, 4]           4,096\n","            ReLU-171           [-1, 2048, 4, 4]               0\n","      Bottleneck-172           [-1, 2048, 4, 4]               0\n","AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n","          Linear-174                   [-1, 10]          20,490\n","================================================================\n","Total params: 23,520,842\n","Trainable params: 23,520,842\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 89.08\n","Params size (MB): 89.72\n","Estimated Total Size (MB): 178.81\n","----------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["## hyperparameter"],"metadata":{"id":"_jHUfrQCnWHN"}},{"cell_type":"code","source":["epochs = 50\n","max_lr = 0.01\n","grad_clip = 0.1\n","weight_decay = 1e-4"],"metadata":{"id":"i7Hp9JWnnVY1","executionInfo":{"status":"ok","timestamp":1642595051242,"user_tz":-540,"elapsed":285,"user":{"displayName":"Sohyun An","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiA5fbxTFul4oSf0J-aANYw-cKEXK7BcQfHqodu=s64","userId":"03040571318498638819"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## optimizer"],"metadata":{"id":"cf3QgwcVnMIL"}},{"cell_type":"code","source":["learning_rate = 1e-2\n","momentum=0.9\n","\n","optimizer = torch.optim.Adam(model.parameters(), max_lr, weight_decay=weight_decay)"],"metadata":{"id":"DsKsyM8MaLgv","executionInfo":{"status":"ok","timestamp":1642595066053,"user_tz":-540,"elapsed":269,"user":{"displayName":"Sohyun An","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiA5fbxTFul4oSf0J-aANYw-cKEXK7BcQfHqodu=s64","userId":"03040571318498638819"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## scheduler"],"metadata":{"id":"NEAYkge3nPd8"}},{"cell_type":"code","source":["scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n","                                                steps_per_epoch=len(loader_train))\n","print(optimizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7DdrChWdPDh1","executionInfo":{"status":"ok","timestamp":1642595107111,"user_tz":-540,"elapsed":285,"user":{"displayName":"Sohyun An","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiA5fbxTFul4oSf0J-aANYw-cKEXK7BcQfHqodu=s64","userId":"03040571318498638819"}},"outputId":"237ebac6-417c-49e9-ab16-b37b0c228747"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    base_momentum: 0.85\n","    betas: (0.95, 0.999)\n","    eps: 1e-08\n","    initial_lr: 0.0004\n","    lr: 0.0003999999999999993\n","    max_lr: 0.01\n","    max_momentum: 0.95\n","    min_lr: 4e-08\n","    weight_decay: 0.0001\n",")\n"]}]},{"cell_type":"code","source":["train(model, optimizer, scheduler, epochs=epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EQhK2qh97ldj","outputId":"7f5d1618-14f3-45ce-afb1-dd59d6fb9bb6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------  Epoch: 1  --------------------\n","Epoch 1\n","Iteration 0, loss = 2.3723\n","Checking accuracy on validation set\n","Got 138 / 1000 correct (13.80)\n","\n","Epoch 1\n","Iteration 100, loss = 1.2447\n","Checking accuracy on validation set\n","Got 624 / 1000 correct (62.40)\n","\n","Epoch 1\n","Iteration 200, loss = 1.0124\n","Checking accuracy on validation set\n","Got 753 / 1000 correct (75.30)\n","\n","Epoch 1\n","Iteration 300, loss = 0.9330\n","Checking accuracy on validation set\n","Got 780 / 1000 correct (78.00)\n","\n","Epoch 1\n","Iteration 400, loss = 0.8002\n","Checking accuracy on validation set\n","Got 788 / 1000 correct (78.80)\n","\n","Epoch 1\n","Iteration 500, loss = 0.3745\n","Checking accuracy on validation set\n","Got 815 / 1000 correct (81.50)\n","\n","Epoch 1\n","Iteration 600, loss = 0.6838\n","Checking accuracy on validation set\n","Got 812 / 1000 correct (81.20)\n","\n","Epoch 1\n","Iteration 700, loss = 0.4303\n","Checking accuracy on validation set\n","Got 823 / 1000 correct (82.30)\n","\n","--------------------  Epoch: 2  --------------------\n","Epoch 2\n","Iteration 0, loss = 0.5229\n","Checking accuracy on validation set\n","Got 810 / 1000 correct (81.00)\n","\n","Epoch 2\n","Iteration 100, loss = 0.6540\n","Checking accuracy on validation set\n","Got 826 / 1000 correct (82.60)\n","\n","Epoch 2\n","Iteration 200, loss = 0.6010\n","Checking accuracy on validation set\n","Got 853 / 1000 correct (85.30)\n","\n","Epoch 2\n","Iteration 300, loss = 0.3308\n","Checking accuracy on validation set\n","Got 831 / 1000 correct (83.10)\n","\n","Epoch 2\n","Iteration 400, loss = 0.4905\n","Checking accuracy on validation set\n","Got 834 / 1000 correct (83.40)\n","\n","Epoch 2\n","Iteration 500, loss = 0.5170\n","Checking accuracy on validation set\n","Got 869 / 1000 correct (86.90)\n","\n","Epoch 2\n","Iteration 600, loss = 0.3297\n","Checking accuracy on validation set\n","Got 860 / 1000 correct (86.00)\n","\n","Epoch 2\n","Iteration 700, loss = 0.4936\n","Checking accuracy on validation set\n","Got 856 / 1000 correct (85.60)\n","\n","--------------------  Epoch: 3  --------------------\n","Epoch 3\n","Iteration 0, loss = 0.3208\n","Checking accuracy on validation set\n","Got 866 / 1000 correct (86.60)\n","\n","Epoch 3\n","Iteration 100, loss = 0.5339\n","Checking accuracy on validation set\n","Got 878 / 1000 correct (87.80)\n","\n","Epoch 3\n","Iteration 200, loss = 0.1648\n","Checking accuracy on validation set\n","Got 870 / 1000 correct (87.00)\n","\n","Epoch 3\n","Iteration 300, loss = 0.3299\n","Checking accuracy on validation set\n","Got 858 / 1000 correct (85.80)\n","\n","Epoch 3\n","Iteration 400, loss = 0.3927\n","Checking accuracy on validation set\n","Got 894 / 1000 correct (89.40)\n","\n","Epoch 3\n","Iteration 500, loss = 0.4573\n","Checking accuracy on validation set\n","Got 889 / 1000 correct (88.90)\n","\n","Epoch 3\n","Iteration 600, loss = 0.2643\n","Checking accuracy on validation set\n","Got 885 / 1000 correct (88.50)\n","\n","Epoch 3\n","Iteration 700, loss = 0.2539\n","Checking accuracy on validation set\n","Got 881 / 1000 correct (88.10)\n","\n","--------------------  Epoch: 4  --------------------\n","Epoch 4\n","Iteration 0, loss = 0.2715\n","Checking accuracy on validation set\n","Got 896 / 1000 correct (89.60)\n","\n","Epoch 4\n","Iteration 100, loss = 0.2586\n","Checking accuracy on validation set\n","Got 888 / 1000 correct (88.80)\n","\n","Epoch 4\n","Iteration 200, loss = 0.3309\n","Checking accuracy on validation set\n","Got 889 / 1000 correct (88.90)\n","\n","Epoch 4\n","Iteration 300, loss = 0.2911\n","Checking accuracy on validation set\n","Got 881 / 1000 correct (88.10)\n","\n","Epoch 4\n","Iteration 400, loss = 0.3504\n","Checking accuracy on validation set\n","Got 897 / 1000 correct (89.70)\n","\n","Epoch 4\n","Iteration 500, loss = 0.3389\n","Checking accuracy on validation set\n","Got 877 / 1000 correct (87.70)\n","\n","Epoch 4\n","Iteration 600, loss = 0.2719\n","Checking accuracy on validation set\n","Got 891 / 1000 correct (89.10)\n","\n","Epoch 4\n","Iteration 700, loss = 0.2002\n","Checking accuracy on validation set\n","Got 905 / 1000 correct (90.50)\n","\n","--------------------  Epoch: 5  --------------------\n","Epoch 5\n","Iteration 0, loss = 0.1532\n","Checking accuracy on validation set\n","Got 904 / 1000 correct (90.40)\n","\n","Epoch 5\n","Iteration 100, loss = 0.2533\n","Checking accuracy on validation set\n","Got 901 / 1000 correct (90.10)\n","\n","Epoch 5\n","Iteration 200, loss = 0.2408\n","Checking accuracy on validation set\n","Got 913 / 1000 correct (91.30)\n","\n","Epoch 5\n","Iteration 300, loss = 0.3013\n","Checking accuracy on validation set\n","Got 886 / 1000 correct (88.60)\n","\n","Epoch 5\n","Iteration 400, loss = 0.3035\n","Checking accuracy on validation set\n","Got 893 / 1000 correct (89.30)\n","\n","Epoch 5\n","Iteration 500, loss = 0.2016\n","Checking accuracy on validation set\n","Got 897 / 1000 correct (89.70)\n","\n","Epoch 5\n","Iteration 600, loss = 0.1285\n","Checking accuracy on validation set\n","Got 915 / 1000 correct (91.50)\n","\n","Epoch 5\n","Iteration 700, loss = 0.3400\n","Checking accuracy on validation set\n","Got 910 / 1000 correct (91.00)\n","\n","--------------------  Epoch: 6  --------------------\n","Epoch 6\n","Iteration 0, loss = 0.2676\n","Checking accuracy on validation set\n","Got 916 / 1000 correct (91.60)\n","\n","Epoch 6\n","Iteration 100, loss = 0.1154\n","Checking accuracy on validation set\n","Got 911 / 1000 correct (91.10)\n","\n","Epoch 6\n","Iteration 200, loss = 0.3333\n","Checking accuracy on validation set\n","Got 898 / 1000 correct (89.80)\n","\n","Epoch 6\n","Iteration 300, loss = 0.2197\n","Checking accuracy on validation set\n","Got 922 / 1000 correct (92.20)\n","\n","Epoch 6\n","Iteration 400, loss = 0.2664\n","Checking accuracy on validation set\n","Got 901 / 1000 correct (90.10)\n","\n","Epoch 6\n","Iteration 500, loss = 0.2771\n","Checking accuracy on validation set\n","Got 905 / 1000 correct (90.50)\n","\n","Epoch 6\n","Iteration 600, loss = 0.1455\n","Checking accuracy on validation set\n","Got 903 / 1000 correct (90.30)\n","\n","Epoch 6\n","Iteration 700, loss = 0.2342\n","Checking accuracy on validation set\n","Got 899 / 1000 correct (89.90)\n","\n","--------------------  Epoch: 7  --------------------\n","Epoch 7\n","Iteration 0, loss = 0.2598\n","Checking accuracy on validation set\n","Got 904 / 1000 correct (90.40)\n","\n","Epoch 7\n","Iteration 100, loss = 0.3866\n","Checking accuracy on validation set\n","Got 917 / 1000 correct (91.70)\n","\n","Epoch 7\n","Iteration 200, loss = 0.2411\n","Checking accuracy on validation set\n","Got 916 / 1000 correct (91.60)\n","\n","Epoch 7\n","Iteration 300, loss = 0.0979\n","Checking accuracy on validation set\n","Got 898 / 1000 correct (89.80)\n","\n","Epoch 7\n","Iteration 400, loss = 0.1544\n","Checking accuracy on validation set\n","Got 911 / 1000 correct (91.10)\n","\n","Epoch 7\n","Iteration 500, loss = 0.2280\n","Checking accuracy on validation set\n","Got 915 / 1000 correct (91.50)\n","\n","Epoch 7\n","Iteration 600, loss = 0.3648\n","Checking accuracy on validation set\n","Got 901 / 1000 correct (90.10)\n","\n","Epoch 7\n","Iteration 700, loss = 0.3001\n","Checking accuracy on validation set\n","Got 911 / 1000 correct (91.10)\n","\n","--------------------  Epoch: 8  --------------------\n","Epoch 8\n","Iteration 0, loss = 0.2748\n","Checking accuracy on validation set\n","Got 904 / 1000 correct (90.40)\n","\n","Epoch 8\n","Iteration 100, loss = 0.2564\n","Checking accuracy on validation set\n","Got 916 / 1000 correct (91.60)\n","\n","Epoch 8\n","Iteration 200, loss = 0.3106\n","Checking accuracy on validation set\n","Got 899 / 1000 correct (89.90)\n","\n","Epoch 8\n","Iteration 300, loss = 0.3106\n","Checking accuracy on validation set\n","Got 898 / 1000 correct (89.80)\n","\n","Epoch 8\n","Iteration 400, loss = 0.1342\n","Checking accuracy on validation set\n","Got 908 / 1000 correct (90.80)\n","\n","Epoch 8\n","Iteration 500, loss = 0.2598\n","Checking accuracy on validation set\n","Got 906 / 1000 correct (90.60)\n","\n","Epoch 8\n","Iteration 600, loss = 0.1681\n","Checking accuracy on validation set\n","Got 917 / 1000 correct (91.70)\n","\n","Epoch 8\n","Iteration 700, loss = 0.1670\n","Checking accuracy on validation set\n","Got 909 / 1000 correct (90.90)\n","\n","--------------------  Epoch: 9  --------------------\n","Epoch 9\n","Iteration 0, loss = 0.1679\n","Checking accuracy on validation set\n","Got 915 / 1000 correct (91.50)\n","\n","Epoch 9\n","Iteration 100, loss = 0.2237\n","Checking accuracy on validation set\n","Got 914 / 1000 correct (91.40)\n","\n","Epoch 9\n","Iteration 200, loss = 0.3292\n","Checking accuracy on validation set\n","Got 897 / 1000 correct (89.70)\n","\n","Epoch 9\n","Iteration 300, loss = 0.0718\n","Checking accuracy on validation set\n","Got 916 / 1000 correct (91.60)\n","\n","Epoch 9\n","Iteration 400, loss = 0.1211\n","Checking accuracy on validation set\n","Got 915 / 1000 correct (91.50)\n","\n","Epoch 9\n","Iteration 500, loss = 0.1564\n","Checking accuracy on validation set\n","Got 924 / 1000 correct (92.40)\n","\n","Epoch 9\n","Iteration 600, loss = 0.2234\n","Checking accuracy on validation set\n","Got 912 / 1000 correct (91.20)\n","\n","Epoch 9\n","Iteration 700, loss = 0.3702\n","Checking accuracy on validation set\n","Got 916 / 1000 correct (91.60)\n","\n","--------------------  Epoch: 10  --------------------\n","Epoch 10\n","Iteration 0, loss = 0.2070\n","Checking accuracy on validation set\n","Got 930 / 1000 correct (93.00)\n","\n","Epoch 10\n","Iteration 100, loss = 0.1360\n","Checking accuracy on validation set\n","Got 927 / 1000 correct (92.70)\n","\n","Epoch 10\n","Iteration 200, loss = 0.1301\n","Checking accuracy on validation set\n","Got 915 / 1000 correct (91.50)\n","\n","Epoch 10\n","Iteration 300, loss = 0.3892\n","Checking accuracy on validation set\n","Got 920 / 1000 correct (92.00)\n","\n","Epoch 10\n","Iteration 400, loss = 0.1963\n","Checking accuracy on validation set\n","Got 928 / 1000 correct (92.80)\n","\n","Epoch 10\n","Iteration 500, loss = 0.1533\n","Checking accuracy on validation set\n","Got 909 / 1000 correct (90.90)\n","\n","Epoch 10\n","Iteration 600, loss = 0.0493\n","Checking accuracy on validation set\n","Got 919 / 1000 correct (91.90)\n","\n","Epoch 10\n","Iteration 700, loss = 0.2735\n","Checking accuracy on validation set\n","Got 913 / 1000 correct (91.30)\n","\n","--------------------  Epoch: 11  --------------------\n","Epoch 11\n","Iteration 0, loss = 0.2292\n","Checking accuracy on validation set\n","Got 924 / 1000 correct (92.40)\n","\n","Epoch 11\n","Iteration 100, loss = 0.1276\n","Checking accuracy on validation set\n","Got 919 / 1000 correct (91.90)\n","\n","Epoch 11\n","Iteration 200, loss = 0.2842\n","Checking accuracy on validation set\n","Got 914 / 1000 correct (91.40)\n","\n","Epoch 11\n","Iteration 300, loss = 0.2418\n","Checking accuracy on validation set\n","Got 926 / 1000 correct (92.60)\n","\n","Epoch 11\n","Iteration 400, loss = 0.2327\n","Checking accuracy on validation set\n","Got 917 / 1000 correct (91.70)\n","\n","Epoch 11\n","Iteration 500, loss = 0.0779\n","Checking accuracy on validation set\n","Got 919 / 1000 correct (91.90)\n","\n","Epoch 11\n","Iteration 600, loss = 0.2326\n","Checking accuracy on validation set\n","Got 925 / 1000 correct (92.50)\n","\n","Epoch 11\n","Iteration 700, loss = 0.1529\n","Checking accuracy on validation set\n","Got 923 / 1000 correct (92.30)\n","\n","--------------------  Epoch: 12  --------------------\n","Epoch 12\n","Iteration 0, loss = 0.1850\n","Checking accuracy on validation set\n","Got 927 / 1000 correct (92.70)\n","\n","Epoch 12\n","Iteration 100, loss = 0.2718\n","Checking accuracy on validation set\n","Got 929 / 1000 correct (92.90)\n","\n","Epoch 12\n","Iteration 200, loss = 0.0945\n","Checking accuracy on validation set\n","Got 911 / 1000 correct (91.10)\n","\n","Epoch 12\n","Iteration 300, loss = 0.1191\n","Checking accuracy on validation set\n","Got 904 / 1000 correct (90.40)\n","\n","Epoch 12\n","Iteration 400, loss = 0.2266\n","Checking accuracy on validation set\n","Got 920 / 1000 correct (92.00)\n","\n","Epoch 12\n","Iteration 500, loss = 0.1056\n","Checking accuracy on validation set\n","Got 918 / 1000 correct (91.80)\n","\n","Epoch 12\n","Iteration 600, loss = 0.1353\n","Checking accuracy on validation set\n","Got 903 / 1000 correct (90.30)\n","\n","Epoch 12\n","Iteration 700, loss = 0.1489\n","Checking accuracy on validation set\n","Got 924 / 1000 correct (92.40)\n","\n","--------------------  Epoch: 13  --------------------\n","Epoch 13\n","Iteration 0, loss = 0.2162\n","Checking accuracy on validation set\n","Got 927 / 1000 correct (92.70)\n","\n","Epoch 13\n","Iteration 100, loss = 0.0707\n","Checking accuracy on validation set\n","Got 907 / 1000 correct (90.70)\n","\n","Epoch 13\n","Iteration 200, loss = 0.1137\n","Checking accuracy on validation set\n","Got 922 / 1000 correct (92.20)\n","\n","Epoch 13\n","Iteration 300, loss = 0.0822\n","Checking accuracy on validation set\n","Got 920 / 1000 correct (92.00)\n","\n","Epoch 13\n","Iteration 400, loss = 0.2052\n","Checking accuracy on validation set\n","Got 926 / 1000 correct (92.60)\n","\n","Epoch 13\n","Iteration 500, loss = 0.1856\n","Checking accuracy on validation set\n","Got 922 / 1000 correct (92.20)\n","\n","Epoch 13\n","Iteration 600, loss = 0.1521\n","Checking accuracy on validation set\n","Got 919 / 1000 correct (91.90)\n","\n","Epoch 13\n","Iteration 700, loss = 0.2070\n","Checking accuracy on validation set\n","Got 909 / 1000 correct (90.90)\n","\n","--------------------  Epoch: 14  --------------------\n","Epoch 14\n","Iteration 0, loss = 0.3716\n","Checking accuracy on validation set\n","Got 921 / 1000 correct (92.10)\n","\n","Epoch 14\n","Iteration 100, loss = 0.1053\n","Checking accuracy on validation set\n","Got 922 / 1000 correct (92.20)\n","\n","Epoch 14\n","Iteration 200, loss = 0.0863\n","Checking accuracy on validation set\n","Got 911 / 1000 correct (91.10)\n","\n","Epoch 14\n","Iteration 300, loss = 0.1214\n","Checking accuracy on validation set\n","Got 913 / 1000 correct (91.30)\n","\n","Epoch 14\n","Iteration 400, loss = 0.1206\n","Checking accuracy on validation set\n","Got 931 / 1000 correct (93.10)\n","\n","Epoch 14\n","Iteration 500, loss = 0.2102\n","Checking accuracy on validation set\n","Got 931 / 1000 correct (93.10)\n","\n","Epoch 14\n","Iteration 600, loss = 0.3826\n","Checking accuracy on validation set\n","Got 909 / 1000 correct (90.90)\n","\n","Epoch 14\n","Iteration 700, loss = 0.2441\n","Checking accuracy on validation set\n","Got 917 / 1000 correct (91.70)\n","\n","--------------------  Epoch: 15  --------------------\n","Epoch 15\n","Iteration 0, loss = 0.0994\n","Checking accuracy on validation set\n","Got 928 / 1000 correct (92.80)\n","\n","Epoch 15\n","Iteration 100, loss = 0.2013\n","Checking accuracy on validation set\n","Got 923 / 1000 correct (92.30)\n","\n","Epoch 15\n","Iteration 200, loss = 0.1563\n","Checking accuracy on validation set\n","Got 926 / 1000 correct (92.60)\n","\n","Epoch 15\n","Iteration 300, loss = 0.1002\n","Checking accuracy on validation set\n","Got 920 / 1000 correct (92.00)\n","\n","Epoch 15\n","Iteration 400, loss = 0.0684\n","Checking accuracy on validation set\n","Got 919 / 1000 correct (91.90)\n","\n","Epoch 15\n","Iteration 500, loss = 0.1456\n","Checking accuracy on validation set\n","Got 929 / 1000 correct (92.90)\n","\n","Epoch 15\n","Iteration 600, loss = 0.1058\n","Checking accuracy on validation set\n","Got 918 / 1000 correct (91.80)\n","\n","Epoch 15\n","Iteration 700, loss = 0.1709\n","Checking accuracy on validation set\n","Got 909 / 1000 correct (90.90)\n","\n","--------------------  Epoch: 16  --------------------\n","Epoch 16\n","Iteration 0, loss = 0.1109\n","Checking accuracy on validation set\n","Got 927 / 1000 correct (92.70)\n","\n","Epoch 16\n","Iteration 100, loss = 0.1128\n","Checking accuracy on validation set\n","Got 931 / 1000 correct (93.10)\n","\n","Epoch 16\n","Iteration 200, loss = 0.0937\n","Checking accuracy on validation set\n","Got 927 / 1000 correct (92.70)\n","\n","Epoch 16\n","Iteration 300, loss = 0.0836\n","Checking accuracy on validation set\n","Got 931 / 1000 correct (93.10)\n","\n","Epoch 16\n","Iteration 400, loss = 0.1162\n","Checking accuracy on validation set\n","Got 919 / 1000 correct (91.90)\n","\n","Epoch 16\n","Iteration 500, loss = 0.2026\n","Checking accuracy on validation set\n","Got 915 / 1000 correct (91.50)\n","\n","Epoch 16\n","Iteration 600, loss = 0.2426\n","Checking accuracy on validation set\n","Got 906 / 1000 correct (90.60)\n","\n","Epoch 16\n","Iteration 700, loss = 0.1282\n","Checking accuracy on validation set\n","Got 916 / 1000 correct (91.60)\n","\n","--------------------  Epoch: 17  --------------------\n","Epoch 17\n","Iteration 0, loss = 0.0868\n","Checking accuracy on validation set\n","Got 926 / 1000 correct (92.60)\n","\n","Epoch 17\n","Iteration 100, loss = 0.1224\n","Checking accuracy on validation set\n","Got 925 / 1000 correct (92.50)\n","\n","Epoch 17\n","Iteration 200, loss = 0.0499\n","Checking accuracy on validation set\n","Got 930 / 1000 correct (93.00)\n","\n","Epoch 17\n","Iteration 300, loss = 0.1461\n","Checking accuracy on validation set\n","Got 937 / 1000 correct (93.70)\n","\n","Epoch 17\n","Iteration 400, loss = 0.0788\n","Checking accuracy on validation set\n","Got 908 / 1000 correct (90.80)\n","\n","Epoch 17\n","Iteration 500, loss = 0.1348\n","Checking accuracy on validation set\n","Got 917 / 1000 correct (91.70)\n","\n","Epoch 17\n","Iteration 600, loss = 0.1775\n","Checking accuracy on validation set\n","Got 909 / 1000 correct (90.90)\n","\n","Epoch 17\n","Iteration 700, loss = 0.1657\n","Checking accuracy on validation set\n","Got 930 / 1000 correct (93.00)\n","\n","--------------------  Epoch: 18  --------------------\n","Epoch 18\n","Iteration 0, loss = 0.2720\n","Checking accuracy on validation set\n","Got 928 / 1000 correct (92.80)\n","\n","Epoch 18\n","Iteration 100, loss = 0.0986\n","Checking accuracy on validation set\n","Got 935 / 1000 correct (93.50)\n","\n","Epoch 18\n","Iteration 200, loss = 0.0536\n","Checking accuracy on validation set\n","Got 929 / 1000 correct (92.90)\n","\n","Epoch 18\n","Iteration 300, loss = 0.1482\n","Checking accuracy on validation set\n","Got 911 / 1000 correct (91.10)\n","\n","Epoch 18\n","Iteration 400, loss = 0.1803\n","Checking accuracy on validation set\n","Got 923 / 1000 correct (92.30)\n","\n","Epoch 18\n","Iteration 500, loss = 0.1838\n","Checking accuracy on validation set\n","Got 919 / 1000 correct (91.90)\n","\n","Epoch 18\n","Iteration 600, loss = 0.1644\n","Checking accuracy on validation set\n","Got 916 / 1000 correct (91.60)\n","\n","Epoch 18\n","Iteration 700, loss = 0.0398\n","Checking accuracy on validation set\n","Got 930 / 1000 correct (93.00)\n","\n","--------------------  Epoch: 19  --------------------\n","Epoch 19\n","Iteration 0, loss = 0.0778\n","Checking accuracy on validation set\n","Got 924 / 1000 correct (92.40)\n","\n","Epoch 19\n","Iteration 100, loss = 0.1042\n","Checking accuracy on validation set\n","Got 923 / 1000 correct (92.30)\n","\n","Epoch 19\n","Iteration 200, loss = 0.0906\n","Checking accuracy on validation set\n","Got 932 / 1000 correct (93.20)\n","\n","Epoch 19\n","Iteration 300, loss = 0.0611\n","Checking accuracy on validation set\n","Got 924 / 1000 correct (92.40)\n","\n","Epoch 19\n","Iteration 400, loss = 0.2229\n","Checking accuracy on validation set\n","Got 927 / 1000 correct (92.70)\n","\n","Epoch 19\n","Iteration 500, loss = 0.0841\n","Checking accuracy on validation set\n","Got 935 / 1000 correct (93.50)\n","\n","Epoch 19\n","Iteration 600, loss = 0.1259\n","Checking accuracy on validation set\n","Got 933 / 1000 correct (93.30)\n","\n","Epoch 19\n","Iteration 700, loss = 0.0924\n","Checking accuracy on validation set\n","Got 933 / 1000 correct (93.30)\n","\n","--------------------  Epoch: 20  --------------------\n","Epoch 20\n","Iteration 0, loss = 0.1198\n","Checking accuracy on validation set\n","Got 929 / 1000 correct (92.90)\n","\n","Epoch 20\n","Iteration 100, loss = 0.0488\n","Checking accuracy on validation set\n","Got 920 / 1000 correct (92.00)\n","\n","Epoch 20\n","Iteration 200, loss = 0.0852\n","Checking accuracy on validation set\n","Got 931 / 1000 correct (93.10)\n","\n","Epoch 20\n","Iteration 300, loss = 0.1230\n","Checking accuracy on validation set\n","Got 925 / 1000 correct (92.50)\n","\n","Epoch 20\n","Iteration 400, loss = 0.1764\n","Checking accuracy on validation set\n","Got 916 / 1000 correct (91.60)\n","\n","Epoch 20\n","Iteration 500, loss = 0.1294\n","Checking accuracy on validation set\n","Got 912 / 1000 correct (91.20)\n","\n","Epoch 20\n","Iteration 600, loss = 0.0946\n","Checking accuracy on validation set\n","Got 930 / 1000 correct (93.00)\n","\n","Epoch 20\n","Iteration 700, loss = 0.0461\n","Checking accuracy on validation set\n","Got 932 / 1000 correct (93.20)\n","\n","--------------------  Epoch: 21  --------------------\n","Epoch 21\n","Iteration 0, loss = 0.1494\n","Checking accuracy on validation set\n","Got 920 / 1000 correct (92.00)\n","\n","Epoch 21\n","Iteration 100, loss = 0.1391\n","Checking accuracy on validation set\n","Got 929 / 1000 correct (92.90)\n","\n","Epoch 21\n","Iteration 200, loss = 0.0601\n","Checking accuracy on validation set\n","Got 921 / 1000 correct (92.10)\n","\n","Epoch 21\n","Iteration 300, loss = 0.0896\n","Checking accuracy on validation set\n","Got 925 / 1000 correct (92.50)\n","\n","Epoch 21\n","Iteration 400, loss = 0.0484\n","Checking accuracy on validation set\n","Got 917 / 1000 correct (91.70)\n","\n","Epoch 21\n","Iteration 500, loss = 0.1145\n","Checking accuracy on validation set\n","Got 929 / 1000 correct (92.90)\n","\n","Epoch 21\n","Iteration 600, loss = 0.0855\n","Checking accuracy on validation set\n","Got 927 / 1000 correct (92.70)\n","\n","Epoch 21\n","Iteration 700, loss = 0.0573\n","Checking accuracy on validation set\n","Got 926 / 1000 correct (92.60)\n","\n","--------------------  Epoch: 22  --------------------\n","Epoch 22\n","Iteration 0, loss = 0.1986\n","Checking accuracy on validation set\n","Got 935 / 1000 correct (93.50)\n","\n","Epoch 22\n","Iteration 100, loss = 0.0866\n","Checking accuracy on validation set\n","Got 936 / 1000 correct (93.60)\n","\n","Epoch 22\n","Iteration 200, loss = 0.0856\n","Checking accuracy on validation set\n","Got 929 / 1000 correct (92.90)\n","\n","Epoch 22\n","Iteration 300, loss = 0.0957\n","Checking accuracy on validation set\n","Got 928 / 1000 correct (92.80)\n","\n","Epoch 22\n","Iteration 400, loss = 0.1438\n","Checking accuracy on validation set\n","Got 937 / 1000 correct (93.70)\n","\n","Epoch 22\n","Iteration 500, loss = 0.1706\n","Checking accuracy on validation set\n","Got 927 / 1000 correct (92.70)\n","\n","Epoch 22\n","Iteration 600, loss = 0.0652\n","Checking accuracy on validation set\n","Got 934 / 1000 correct (93.40)\n","\n","Epoch 22\n","Iteration 700, loss = 0.1215\n","Checking accuracy on validation set\n","Got 928 / 1000 correct (92.80)\n","\n","--------------------  Epoch: 23  --------------------\n","Epoch 23\n","Iteration 0, loss = 0.0344\n","Checking accuracy on validation set\n","Got 936 / 1000 correct (93.60)\n","\n","Epoch 23\n","Iteration 100, loss = 0.1039\n","Checking accuracy on validation set\n","Got 933 / 1000 correct (93.30)\n","\n","Epoch 23\n","Iteration 200, loss = 0.0734\n","Checking accuracy on validation set\n","Got 932 / 1000 correct (93.20)\n","\n","Epoch 23\n","Iteration 300, loss = 0.0778\n","Checking accuracy on validation set\n","Got 924 / 1000 correct (92.40)\n","\n","Epoch 23\n","Iteration 400, loss = 0.1958\n","Checking accuracy on validation set\n","Got 929 / 1000 correct (92.90)\n","\n","Epoch 23\n","Iteration 500, loss = 0.1611\n","Checking accuracy on validation set\n","Got 930 / 1000 correct (93.00)\n","\n","Epoch 23\n","Iteration 600, loss = 0.2205\n","Checking accuracy on validation set\n","Got 918 / 1000 correct (91.80)\n","\n","Epoch 23\n","Iteration 700, loss = 0.0704\n","Checking accuracy on validation set\n","Got 924 / 1000 correct (92.40)\n","\n","--------------------  Epoch: 24  --------------------\n","Epoch 24\n","Iteration 0, loss = 0.0483\n","Checking accuracy on validation set\n","Got 928 / 1000 correct (92.80)\n","\n","Epoch 24\n","Iteration 100, loss = 0.0460\n","Checking accuracy on validation set\n","Got 935 / 1000 correct (93.50)\n","\n","Epoch 24\n","Iteration 200, loss = 0.0972\n","Checking accuracy on validation set\n","Got 931 / 1000 correct (93.10)\n","\n","Epoch 24\n","Iteration 300, loss = 0.1906\n","Checking accuracy on validation set\n","Got 925 / 1000 correct (92.50)\n","\n","Epoch 24\n","Iteration 400, loss = 0.0898\n","Checking accuracy on validation set\n","Got 924 / 1000 correct (92.40)\n","\n","Epoch 24\n","Iteration 500, loss = 0.1208\n","Checking accuracy on validation set\n","Got 920 / 1000 correct (92.00)\n","\n","Epoch 24\n","Iteration 600, loss = 0.0795\n","Checking accuracy on validation set\n","Got 920 / 1000 correct (92.00)\n","\n","Epoch 24\n","Iteration 700, loss = 0.0678\n","Checking accuracy on validation set\n","Got 933 / 1000 correct (93.30)\n","\n","--------------------  Epoch: 25  --------------------\n","Epoch 25\n","Iteration 0, loss = 0.1791\n","Checking accuracy on validation set\n","Got 923 / 1000 correct (92.30)\n","\n","Epoch 25\n","Iteration 100, loss = 0.1349\n","Checking accuracy on validation set\n","Got 928 / 1000 correct (92.80)\n","\n","Epoch 25\n","Iteration 200, loss = 0.2055\n","Checking accuracy on validation set\n","Got 923 / 1000 correct (92.30)\n","\n","Epoch 25\n","Iteration 300, loss = 0.1737\n","Checking accuracy on validation set\n","Got 918 / 1000 correct (91.80)\n","\n","Epoch 25\n","Iteration 400, loss = 0.0663\n","Checking accuracy on validation set\n","Got 927 / 1000 correct (92.70)\n","\n","Epoch 25\n","Iteration 500, loss = 0.1648\n","Checking accuracy on validation set\n","Got 929 / 1000 correct (92.90)\n","\n","Epoch 25\n","Iteration 600, loss = 0.0639\n","Checking accuracy on validation set\n","Got 927 / 1000 correct (92.70)\n","\n","Epoch 25\n","Iteration 700, loss = 0.0906\n","Checking accuracy on validation set\n","Got 922 / 1000 correct (92.20)\n","\n","--------------------  Epoch: 26  --------------------\n","Epoch 26\n","Iteration 0, loss = 0.1286\n","Checking accuracy on validation set\n","Got 929 / 1000 correct (92.90)\n","\n","Epoch 26\n","Iteration 100, loss = 0.1031\n","Checking accuracy on validation set\n","Got 938 / 1000 correct (93.80)\n","\n","Epoch 26\n","Iteration 200, loss = 0.0328\n","Checking accuracy on validation set\n","Got 933 / 1000 correct (93.30)\n","\n","Epoch 26\n","Iteration 300, loss = 0.2207\n","Checking accuracy on validation set\n","Got 922 / 1000 correct (92.20)\n","\n","Epoch 26\n","Iteration 400, loss = 0.1093\n","Checking accuracy on validation set\n","Got 936 / 1000 correct (93.60)\n","\n","Epoch 26\n","Iteration 500, loss = 0.1026\n","Checking accuracy on validation set\n","Got 931 / 1000 correct (93.10)\n","\n","Epoch 26\n","Iteration 600, loss = 0.0543\n","Checking accuracy on validation set\n","Got 938 / 1000 correct (93.80)\n","\n","Epoch 26\n","Iteration 700, loss = 0.1718\n","Checking accuracy on validation set\n","Got 930 / 1000 correct (93.00)\n","\n","--------------------  Epoch: 27  --------------------\n","Epoch 27\n","Iteration 0, loss = 0.0838\n","Checking accuracy on validation set\n","Got 928 / 1000 correct (92.80)\n","\n","Epoch 27\n","Iteration 100, loss = 0.0850\n","Checking accuracy on validation set\n","Got 932 / 1000 correct (93.20)\n","\n","Epoch 27\n","Iteration 200, loss = 0.1759\n","Checking accuracy on validation set\n","Got 930 / 1000 correct (93.00)\n","\n","Epoch 27\n","Iteration 300, loss = 0.0233\n","Checking accuracy on validation set\n","Got 922 / 1000 correct (92.20)\n","\n","Epoch 27\n","Iteration 400, loss = 0.0363\n","Checking accuracy on validation set\n","Got 925 / 1000 correct (92.50)\n","\n","Epoch 27\n","Iteration 500, loss = 0.1412\n","Checking accuracy on validation set\n","Got 931 / 1000 correct (93.10)\n","\n","Epoch 27\n","Iteration 600, loss = 0.0452\n","Checking accuracy on validation set\n","Got 936 / 1000 correct (93.60)\n","\n","Epoch 27\n","Iteration 700, loss = 0.0568\n","Checking accuracy on validation set\n","Got 929 / 1000 correct (92.90)\n","\n","--------------------  Epoch: 28  --------------------\n","Epoch 28\n","Iteration 0, loss = 0.0576\n","Checking accuracy on validation set\n","Got 938 / 1000 correct (93.80)\n","\n","Epoch 28\n","Iteration 100, loss = 0.0766\n","Checking accuracy on validation set\n","Got 935 / 1000 correct (93.50)\n","\n","Epoch 28\n","Iteration 200, loss = 0.1390\n","Checking accuracy on validation set\n","Got 923 / 1000 correct (92.30)\n","\n","Epoch 28\n","Iteration 300, loss = 0.0952\n","Checking accuracy on validation set\n","Got 927 / 1000 correct (92.70)\n","\n","Epoch 28\n","Iteration 400, loss = 0.0384\n","Checking accuracy on validation set\n","Got 925 / 1000 correct (92.50)\n","\n","Epoch 28\n","Iteration 500, loss = 0.0842\n","Checking accuracy on validation set\n","Got 925 / 1000 correct (92.50)\n","\n","Epoch 28\n","Iteration 600, loss = 0.1210\n","Checking accuracy on validation set\n","Got 927 / 1000 correct (92.70)\n","\n","Epoch 28\n","Iteration 700, loss = 0.1549\n","Checking accuracy on validation set\n","Got 929 / 1000 correct (92.90)\n","\n","--------------------  Epoch: 29  --------------------\n","Epoch 29\n","Iteration 0, loss = 0.0775\n","Checking accuracy on validation set\n","Got 931 / 1000 correct (93.10)\n","\n","Epoch 29\n","Iteration 100, loss = 0.0225\n","Checking accuracy on validation set\n","Got 934 / 1000 correct (93.40)\n","\n","Epoch 29\n","Iteration 200, loss = 0.0902\n","Checking accuracy on validation set\n","Got 926 / 1000 correct (92.60)\n","\n","Epoch 29\n","Iteration 300, loss = 0.0588\n","Checking accuracy on validation set\n","Got 937 / 1000 correct (93.70)\n","\n","Epoch 29\n","Iteration 400, loss = 0.0428\n","Checking accuracy on validation set\n","Got 925 / 1000 correct (92.50)\n","\n","Epoch 29\n","Iteration 500, loss = 0.1972\n","Checking accuracy on validation set\n","Got 913 / 1000 correct (91.30)\n","\n","Epoch 29\n","Iteration 600, loss = 0.1333\n","Checking accuracy on validation set\n","Got 940 / 1000 correct (94.00)\n","\n","Epoch 29\n","Iteration 700, loss = 0.0917\n","Checking accuracy on validation set\n","Got 932 / 1000 correct (93.20)\n","\n","--------------------  Epoch: 30  --------------------\n","Epoch 30\n","Iteration 0, loss = 0.0598\n","Checking accuracy on validation set\n","Got 920 / 1000 correct (92.00)\n","\n","Epoch 30\n","Iteration 100, loss = 0.0547\n","Checking accuracy on validation set\n","Got 938 / 1000 correct (93.80)\n","\n","Epoch 30\n","Iteration 200, loss = 0.0565\n","Checking accuracy on validation set\n","Got 939 / 1000 correct (93.90)\n","\n","Epoch 30\n","Iteration 300, loss = 0.3890\n","Checking accuracy on validation set\n","Got 923 / 1000 correct (92.30)\n","\n","Epoch 30\n","Iteration 400, loss = 0.2100\n","Checking accuracy on validation set\n","Got 937 / 1000 correct (93.70)\n","\n","Epoch 30\n","Iteration 500, loss = 0.0439\n","Checking accuracy on validation set\n","Got 936 / 1000 correct (93.60)\n","\n","Epoch 30\n","Iteration 600, loss = 0.0602\n","Checking accuracy on validation set\n","Got 943 / 1000 correct (94.30)\n","\n","Epoch 30\n","Iteration 700, loss = 0.1503\n","Checking accuracy on validation set\n","Got 933 / 1000 correct (93.30)\n","\n","--------------------  Epoch: 31  --------------------\n","Epoch 31\n","Iteration 0, loss = 0.0746\n","Checking accuracy on validation set\n","Got 930 / 1000 correct (93.00)\n","\n","Epoch 31\n","Iteration 100, loss = 0.0461\n","Checking accuracy on validation set\n","Got 938 / 1000 correct (93.80)\n","\n","Epoch 31\n","Iteration 200, loss = 0.1574\n","Checking accuracy on validation set\n","Got 925 / 1000 correct (92.50)\n","\n","Epoch 31\n","Iteration 300, loss = 0.1734\n","Checking accuracy on validation set\n","Got 944 / 1000 correct (94.40)\n","\n","Epoch 31\n","Iteration 400, loss = 0.1136\n","Checking accuracy on validation set\n","Got 938 / 1000 correct (93.80)\n","\n","Epoch 31\n","Iteration 500, loss = 0.0481\n","Checking accuracy on validation set\n","Got 936 / 1000 correct (93.60)\n","\n","Epoch 31\n","Iteration 600, loss = 0.1418\n","Checking accuracy on validation set\n","Got 933 / 1000 correct (93.30)\n","\n","Epoch 31\n","Iteration 700, loss = 0.0791\n","Checking accuracy on validation set\n","Got 940 / 1000 correct (94.00)\n","\n","--------------------  Epoch: 32  --------------------\n","Epoch 32\n","Iteration 0, loss = 0.0672\n","Checking accuracy on validation set\n","Got 942 / 1000 correct (94.20)\n","\n","Epoch 32\n","Iteration 100, loss = 0.0126\n","Checking accuracy on validation set\n","Got 925 / 1000 correct (92.50)\n","\n","Epoch 32\n","Iteration 200, loss = 0.0357\n","Checking accuracy on validation set\n","Got 922 / 1000 correct (92.20)\n","\n","Epoch 32\n","Iteration 300, loss = 0.0612\n","Checking accuracy on validation set\n","Got 940 / 1000 correct (94.00)\n","\n","Epoch 32\n","Iteration 400, loss = 0.1574\n","Checking accuracy on validation set\n","Got 931 / 1000 correct (93.10)\n","\n","Epoch 32\n","Iteration 500, loss = 0.1224\n","Checking accuracy on validation set\n","Got 933 / 1000 correct (93.30)\n","\n","Epoch 32\n","Iteration 600, loss = 0.1301\n","Checking accuracy on validation set\n","Got 923 / 1000 correct (92.30)\n","\n","Epoch 32\n","Iteration 700, loss = 0.1736\n","Checking accuracy on validation set\n","Got 937 / 1000 correct (93.70)\n","\n","--------------------  Epoch: 33  --------------------\n","Epoch 33\n","Iteration 0, loss = 0.0790\n","Checking accuracy on validation set\n","Got 931 / 1000 correct (93.10)\n","\n","Epoch 33\n","Iteration 100, loss = 0.0987\n","Checking accuracy on validation set\n","Got 935 / 1000 correct (93.50)\n","\n","Epoch 33\n","Iteration 200, loss = 0.0968\n","Checking accuracy on validation set\n","Got 928 / 1000 correct (92.80)\n","\n","Epoch 33\n","Iteration 300, loss = 0.1662\n","Checking accuracy on validation set\n","Got 920 / 1000 correct (92.00)\n","\n","Epoch 33\n","Iteration 400, loss = 0.1143\n","Checking accuracy on validation set\n","Got 922 / 1000 correct (92.20)\n","\n","Epoch 33\n","Iteration 500, loss = 0.1471\n","Checking accuracy on validation set\n","Got 924 / 1000 correct (92.40)\n","\n"]}]},{"cell_type":"code","source":["best_model = model\n","test_acc = check_accuracy(loader_test, best_model)"],"metadata":{"id":"QXV9ZTgM7_Wm"},"execution_count":null,"outputs":[]}]}